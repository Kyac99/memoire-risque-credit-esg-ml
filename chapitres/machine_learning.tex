\chapter{Application des modèles de Machine Learning}

\section{Constitution du jeu de données et prétraitement}

La qualité des données et leur préparation appropriée constituent des étapes fondamentales pour assurer la pertinence et la fiabilité des modèles de Machine Learning appliqués au risque de crédit. Cette section détaille le processus de collecte, d'organisation et de transformation des données utilisées dans notre étude.

\subsection{Sources de données financières et ESG}

Notre jeu de données intègre des informations provenant de multiples sources, combinant données financières traditionnelles et métriques ESG :

\subsubsection{Données financières fondamentales}
\begin{itemize}
  \item \textbf{Refinitiv Eikon/Datastream} : Extraction des états financiers trimestriels et annuels des émetteurs sur la période 2010-2024, incluant les principaux ratios (levier, couverture des intérêts, marges, etc.)
  \item \textbf{Bloomberg Terminal} : Données complémentaires sur la structure de capital et les événements de crédit
  \item \textbf{S\&P Capital IQ} : Ratios sectoriels et indicateurs de performance relatifs
\end{itemize}

\subsubsection{Données de marché obligataire}
\begin{itemize}
  \item \textbf{TRACE (Trade Reporting and Compliance Engine)} : Données de transaction sur le marché secondaire américain
  \item \textbf{Markit iBoxx} : Indices obligataires et données de prix pour les marchés européens et asiatiques
  \item \textbf{ICE BofA Indices} : Historiques de spreads par notation et secteur
\end{itemize}

\subsubsection{Données ESG spécifiques}
\begin{itemize}
  \item \textbf{MSCI ESG Research} : Scores ESG globaux et sous-scores par pilier (E, S, G) de 2015 à 2024
  \item \textbf{Sustainalytics} : Évaluations des risques ESG et scores de controverse
  \item \textbf{Carbon Disclosure Project (CDP)} : Données d'émissions carbone (scopes 1, 2 et 3 lorsque disponibles)
  \item \textbf{Corporate Knights} : Indicateurs de durabilité complémentaires
\end{itemize}

\subsubsection{Données macroéconomiques et sectorielles}
\begin{itemize}
  \item \textbf{Banques centrales (Fed, BCE)} : Taux directeurs, indicateurs de conditions financières
  \item \textbf{OCDE et FMI} : Prévisions de croissance par pays et région
  \item \textbf{IHS Markit PMI} : Indices des directeurs d'achat et indicateurs d'activité sectorielle
\end{itemize}

L'horizon temporel retenu s'étend de janvier 2015 à décembre 2023, permettant ainsi de capturer différents cycles économiques et l'évolution progressive de l'intégration des critères ESG.

\subsection{Nettoyage et traitement des valeurs manquantes}

Le traitement des données brutes a nécessité plusieurs étapes de nettoyage et d'harmonisation :

\subsubsection{Détection et correction des anomalies}
\begin{itemize}
  \item Identification des valeurs aberrantes par analyse univariée (Z-score) et multivariée (distance de Mahalanobis)
  \item Vérification manuelle des cas extrêmes pour distinguer les erreurs de mesure des événements exceptionnels
  \item Winsorisation à 1\% et 99\% pour limiter l'impact des valeurs extrêmes sans les éliminer totalement
\end{itemize}

\subsubsection{Gestion des valeurs manquantes}
\begin{itemize}
  \item Analyse des patterns de valeurs manquantes (MCAR, MAR, MNAR)
  \item Approches différenciées selon la nature des données :
  \begin{itemize}
    \item Pour les variables financières fondamentales : imputation par la dernière valeur connue (LOCF) pour les séries temporelles
    \item Pour les scores ESG : combinaison d'imputations par la moyenne sectorielle et de techniques d'imputation multiple
    \item Pour les données de marché : interpolation pour les courtes périodes d'indisponibilité
  \end{itemize}
\end{itemize}

\subsubsection{Harmonisation des fréquences}
\begin{itemize}
  \item Agrégation temporelle pour aligner les données sur une fréquence trimestrielle
  \item Méthodes d'interpolation pour les indicateurs à basse fréquence (annuelle)
\end{itemize}

Le taux de complétude final atteint 98,3\% pour les variables financières et 92,1\% pour les métriques ESG, assurant ainsi une base solide pour l'analyse.

\subsection{Transformation des variables}

La préparation des données a également impliqué plusieurs transformations pour optimiser l'apprentissage des modèles :

\subsubsection{Normalisation et standardisation}
\begin{itemize}
  \item Standardisation (z-score) pour les variables continues utilisées dans les modèles sensibles à l'échelle (régression logistique, SVM)
  \item Normalisation Min-Max pour les variables destinées aux réseaux de neurones
  \item Transformation logarithmique pour les variables à distribution fortement asymétrique (taille d'actifs, volumes d'émission)
\end{itemize}

\subsubsection{Création de variables dérivées}
\begin{itemize}
  \item Ratios composites combinant informations financières et ESG
  \item Variables de momentum capturant la dynamique d'évolution des métriques
  \item Indicateurs d'écart par rapport aux moyennes sectorielles
  \item Variables d'interaction entre facteurs ESG et contexte macroéconomique
\end{itemize}

\subsubsection{Réduction de dimensionnalité}
\begin{itemize}
  \item Analyse en composantes principales (ACP) sur les variables financières hautement corrélées
  \item Conservation des composantes expliquant 95\% de la variance totale
  \item Analyse factorielle pour les sous-scores ESG, permettant d'identifier des facteurs latents
\end{itemize}

\subsubsection{Encodage des variables catégorielles}
\begin{itemize}
  \item One-hot encoding pour les variables nominales avec peu de modalités
  \item Target encoding pour les variables à haute cardinalité (secteurs détaillés, pays)
  \item Encodage ordonné pour les notations de crédit, préservant la relation d'ordre
\end{itemize}

\subsection{Constitution des ensembles d'entraînement et de test}

La division du jeu de données a été réalisée avec une attention particulière aux spécificités des données financières et ESG :

\subsubsection{Division temporelle}
\begin{itemize}
  \item Ensemble d'entraînement : janvier 2015 - décembre 2020 (70\% des données)
  \item Ensemble de validation : janvier 2021 - juin 2022 (15\% des données)
  \item Ensemble de test : juillet 2022 - décembre 2023 (15\% des données)
\end{itemize}

Cette approche respecte la temporalité des données et évite le risque de fuite d'information future dans l'entraînement des modèles.

\subsubsection{Stratification}
\begin{itemize}
  \item Conservation de la distribution des classes de notation dans chaque sous-ensemble
  \item Maintien de la représentativité sectorielle et géographique
\end{itemize}

\subsubsection{Validation croisée adaptée}
\begin{itemize}
  \item Validation croisée temporelle (time series cross-validation) avec fenêtres glissantes
  \item 5 plis temporels avec chevauchement limité pour maximiser l'utilisation des données tout en respectant leur séquentialité
\end{itemize}

Le jeu de données final comprend 2 287 émetteurs obligataires, totalisant 14 592 observations trimestrielles et 217 variables explicatives (105 financières, 78 ESG et 34 macroéconomiques/sectorielles).

\section{Implémentation des modèles de Machine Learning}

La modélisation du risque de crédit intégrant les facteurs ESG nécessite des approches capables de capturer des relations complexes et non-linéaires entre de nombreuses variables. Cette section présente les différents algorithmes de Machine Learning implémentés, leurs paramètres et le processus d'optimisation.

\subsection{Sélection des algorithmes}

Notre approche est fondée sur une comparaison de plusieurs familles d'algorithmes, chacune présentant des caractéristiques distinctes pertinentes pour notre problématique :

\subsubsection{Algorithmes d'ensemble basés sur les arbres de décision}
\begin{itemize}
  \item \textbf{Random Forest} : Offre une excellente capacité à gérer des variables de différentes natures et échelles, tout en limitant le risque de surapprentissage par la diversification des arbres.
  \item \textbf{Gradient Boosting (XGBoost, LightGBM)} : Particulièrement performants pour capturer des relations complexes grâce à leur apprentissage séquentiel optimisé. XGBoost est reconnu pour sa robustesse face aux valeurs manquantes et aux données déséquilibrées.
  \item \textbf{CatBoost} : Spécialement conçu pour gérer efficacement les variables catégorielles, nombreuses dans notre jeu de données (secteurs, pays, notations).
\end{itemize}

\subsubsection{Réseaux de neurones}
\begin{itemize}
  \item \textbf{Perceptron multicouche (MLP)} : Architecture classique pour la classification, avec capacité à modéliser des relations non-linéaires complexes.
  \item \textbf{Long Short-Term Memory (LSTM)} : Réseau récurrent adapté aux séquences temporelles, permettant de capturer les dépendances à long terme dans l'évolution des métriques financières et ESG.
  \item \textbf{Réseau de neurones convolutif (CNN)} : Appliqué aux séries temporelles multivariées des indicateurs financiers et ESG, offrant une analyse multi-échelle des patterns temporels.
\end{itemize}

\subsubsection{Méthodes de régression avancées}
\begin{itemize}
  \item \textbf{Régression logistique régularisée (Lasso, Ridge, ElasticNet)} : Version pénalisée du modèle classique, offrant une meilleure généralisation et sélection automatique des variables pertinentes.
  \item \textbf{Support Vector Machines (SVM)} : Particulièrement adapté aux problèmes de classification binaire avec frontières de décision complexes.
\end{itemize}

\subsubsection{Modèles hybrides et ensembles}
\begin{itemize}
  \item \textbf{Stacking} : Combinaison de modèles de différentes familles pour exploiter leurs forces complémentaires.
  \item \textbf{Modèles hybrides financiers-ESG} : Architectures spécifiques intégrant séparément puis conjointement les facteurs financiers traditionnels et les métriques ESG.
\end{itemize}

Pour cette étude, nous avons implémenté ces modèles en utilisant les bibliothèques Python scikit-learn, XGBoost, PyTorch et Keras/TensorFlow.

\subsection{Paramétrage et optimisation des modèles}

L'optimisation des hyperparamètres constitue une étape cruciale pour assurer la performance et la généralisation des modèles. Notre approche d'optimisation s'est déroulée en deux phases :

\subsubsection{Phase d'exploration initiale}
\begin{itemize}
  \item Recherche aléatoire (Random Search) sur un large espace d'hyperparamètres
  \item Validation croisée temporelle à 5 plis pour chaque configuration
  \item Métrique principale d'optimisation : AUC-ROC (Area Under the Receiver Operating Characteristic curve)
  \item Métriques secondaires : précision, rappel, F1-score et log-loss
\end{itemize}

\subsubsection{Phase d'optimisation fine}
\begin{itemize}
  \item Optimisation bayésienne autour des zones prometteuses identifiées lors de la phase initiale
  \item Utilisation de la bibliothèque Optuna avec l'algorithme Tree-structured Parzen Estimator (TPE)
  \item Incorporation de contraintes pratiques (temps d'entraînement, complexité du modèle)
\end{itemize}

Les principaux hyperparamètres optimisés pour chaque modèle incluent :

\begin{itemize}
  \item \textbf{Random Forest} :
  \begin{itemize}
    \item Nombre d'arbres : 500 (sélectionné dans l'intervalle [100, 1000])
    \item Profondeur maximale : 12 (intervalle [5, 20])
    \item Nombre minimal d'échantillons par feuille : 10 (intervalle [1, 50])
    \item Critère de division : Gini
  \end{itemize}

  \item \textbf{XGBoost} :
  \begin{itemize}
    \item Taux d'apprentissage : 0.03 (intervalle [0.01, 0.1])
    \item Profondeur maximale : 8 (intervalle [3, 12])
    \item Gamma (régularisation) : 1.2 (intervalle [0, 5])
    \item Ratio de sous-échantillonnage : 0.8 (intervalle [0.6, 1.0])
    \item Alpha L1 : 0.5, Lambda L2 : 1.0
  \end{itemize}

  \item \textbf{LSTM} :
  \begin{itemize}
    \item Architecture : 2 couches LSTM (128 et 64 unités)
    \item Dropout : 0.3 (intervalle [0.1, 0.5])
    \item Optimiseur : Adam avec taux d'apprentissage de 0.001
    \item Taille de batch : 64
    \item Nombre d'époques : 100 avec early stopping (patience de 10 époques)
  \end{itemize}

  \item \textbf{Modèle de stacking} :
  \begin{itemize}
    \item Modèles de base : XGBoost, LightGBM, CatBoost, SVM
    \item Méta-modèle : Régression logistique régularisée
    \item Validation croisée interne : 5 plis temporels
  \end{itemize}
\end{itemize}

La complexité des modèles a été calibrée pour éviter le surapprentissage, particulièrement important dans le contexte financier où les données d'entraînement peuvent ne pas être représentatives des conditions futures de marché.

\subsection{Approches spécifiques pour l'intégration des facteurs ESG}

L'intégration des facteurs ESG dans les modèles de Machine Learning a été réalisée selon trois approches distinctes, permettant d'évaluer différentes stratégies :

\subsubsection{Approche unifiée} 
Toutes les variables (financières et ESG) sont considérées au même niveau dans le modèle, sans distinction a priori.

\subsubsection{Approche modulaire} 
Développement de sous-modèles spécialisés (module financier et module ESG) dont les prédictions sont ensuite combinées par un méta-modèle.

\subsubsection{Approche séquentielle} 
Construction d'un modèle de base sur les variables financières, puis incorporation des facteurs ESG comme variables de correction ou d'ajustement.

Ces trois approches ont été systématiquement comparées pour évaluer la méthode la plus efficace d'intégration des critères ESG dans la modélisation du risque de crédit.

\section{Évaluation et interprétation des résultats}

L'évaluation rigoureuse des modèles de Machine Learning et l'interprétation de leurs résultats sont essentielles pour en assurer la pertinence pratique dans la gestion du risque de crédit. Cette section présente les performances obtenues et analyse l'importance relative des différentes variables, en particulier des facteurs ESG.

\subsection{Comparaison des performances des modèles}

Les performances des différents modèles ont été évaluées sur l'ensemble de test (juillet 2022 - décembre 2023) selon plusieurs métriques complémentaires :

\begin{table}[htbp]
  \centering
  \caption{Comparaison des performances des modèles}
  \begin{tabular}{lccccc}
    \toprule
    \textbf{Modèle} & \textbf{AUC-ROC} & \textbf{Précision} & \textbf{Rappel} & \textbf{F1-Score} & \textbf{Log-Loss} \\
    \midrule
    Random Forest & 0,856 & 0,792 & 0,738 & 0,764 & 0,452 \\
    XGBoost & 0,881 & 0,815 & 0,763 & 0,788 & 0,412 \\
    LightGBM & 0,873 & 0,807 & 0,759 & 0,782 & 0,429 \\
    CatBoost & 0,868 & 0,804 & 0,751 & 0,776 & 0,435 \\
    LSTM & 0,859 & 0,788 & 0,764 & 0,776 & 0,447 \\
    MLP & 0,835 & 0,775 & 0,723 & 0,748 & 0,478 \\
    SVM & 0,822 & 0,769 & 0,711 & 0,739 & 0,496 \\
    Logistique (ElasticNet) & 0,804 & 0,753 & 0,698 & 0,724 & 0,521 \\
    Stacking & \textbf{0,893} & \textbf{0,827} & \textbf{0,775} & \textbf{0,800} & \textbf{0,394} \\
    \bottomrule
  \end{tabular}
\end{table}

\begin{table}[htbp]
  \centering
  \caption{Analyse comparative par approche d'intégration ESG}
  \begin{tabular}{lcc}
    \toprule
    \textbf{Approche} & \textbf{AUC-ROC moyen} & \textbf{Gain vs. modèles purement financiers} \\
    \midrule
    Sans ESG (référence) & 0,821 & - \\
    ESG - Approche unifiée & 0,872 & +6,2\% \\
    ESG - Approche modulaire & \textbf{0,884} & \textbf{+7,7\%} \\
    ESG - Approche séquentielle & 0,865 & +5,4\% \\
    \bottomrule
  \end{tabular}
\end{table}

Ces résultats mettent en évidence plusieurs éléments significatifs :

\begin{enumerate}
  \item \textbf{Supériorité des modèles d'ensemble} : XGBoost et le stacking présentent les meilleures performances globales, confirmant l'efficacité des approches ensemblistes pour cette problématique.

  \item \textbf{Apport substantiel des facteurs ESG} : L'inclusion des variables ESG améliore significativement les performances prédictives, avec un gain moyen de 6,4\% en AUC-ROC par rapport aux modèles n'utilisant que des variables financières traditionnelles.

  \item \textbf{Efficacité de l'approche modulaire} : La stratégie consistant à développer des modules spécialisés par type de données avant de les combiner s'avère la plus performante, suggérant que les facteurs ESG et financiers capturent des dimensions complémentaires du risque.

  \item \textbf{Performance temporelle} : L'analyse des erreurs par période montre une meilleure robustesse des modèles intégrant les facteurs ESG lors des périodes de volatilité accrue (T4 2022, T2 2023), confirmant leur valeur ajoutée dans la détection précoce des détériorations de crédit.
\end{enumerate}

\subsection{Importance des variables et analyse de l'impact ESG}

L'analyse de l'importance des variables offre des insights précieux sur les facteurs déterminants du risque de crédit et la contribution spécifique des critères ESG :

\subsubsection{Variables financières dominantes (importance relative moyenne)}
\begin{enumerate}
  \item Ratio de couverture des intérêts (Interest Coverage Ratio) : 8,7\%
  \item Ratio d'endettement (Debt/EBITDA) : 7,9\%
  \item Marge opérationnelle : 6,3\%
  \item Free Cash Flow / Dette totale : 5,8\%
  \item Volatilité des bénéfices (sur 8 trimestres) : 4,9\%
\end{enumerate}

\subsubsection{Variables ESG les plus influentes}
\begin{enumerate}
  \item Score de gouvernance global : 5,2\%
  \item Intensité carbone (Scope 1+2) : 4,3\%
  \item Controverses majeures (indicateur binaire) : 3,7\%
  \item Qualité du management du capital humain : 3,5\%
  \item Exposition aux risques climatiques physiques : 3,2\%
\end{enumerate}

\subsubsection{Importance relative par pilier ESG}
\begin{itemize}
  \item Gouvernance : 42\% de l'importance ESG totale
  \item Environnement : 35\% de l'importance ESG totale
  \item Social : 23\% de l'importance ESG totale
\end{itemize}

\subsubsection{Analyse sectorielle de l'impact ESG}

\begin{table}[htbp]
  \centering
  \caption{Importance sectorielle des facteurs ESG}
  \begin{tabular}{lcc}
    \toprule
    \textbf{Secteur} & \textbf{Importance relative des facteurs ESG} & \textbf{Facteur ESG dominant} \\
    \midrule
    Énergie & 25,3\% & Stratégie climatique et émissions \\
    Matériaux & 23,7\% & Gestion environnementale et biodiversité \\
    Industrie & 19,8\% & Efficacité énergétique et émissions \\
    Consommation discrétionnaire & 17,4\% & Chaîne d'approvisionnement et droits humains \\
    Consommation de base & 16,9\% & Gestion des ressources naturelles \\
    Santé & 15,2\% & Éthique des affaires et gouvernance \\
    Finance & 21,5\% & Structure de gouvernance et transparence \\
    Technologies & 14,3\% & Gouvernance des données et cybersécurité \\
    Télécommunications & 16,1\% & Gouvernance et fracture numérique \\
    Services publics & 24,8\% & Mix énergétique et émissions \\
    Immobilier & 20,2\% & Efficacité énergétique des bâtiments \\
    \bottomrule
  \end{tabular}
\end{table}

Cette analyse détaillée révèle plusieurs insights importants :

\begin{enumerate}
  \item \textbf{Complémentarité des facteurs ESG et financiers} : Les variables ESG n'éclipsent pas les indicateurs financiers traditionnels mais apportent une dimension complémentaire, particulièrement pertinente pour l'anticipation des risques à moyen-long terme.

  \item \textbf{Prédominance de la gouvernance} : Parmi les facteurs ESG, la gouvernance conserve l'influence la plus significative sur le risque de crédit, confirmant les conclusions de nombreuses études antérieures.

  \item \textbf{Hétérogénéité sectorielle} : L'importance relative des facteurs ESG varie considérablement selon les secteurs, atteignant 25\% dans l'énergie et les utilities, contre environ 15\% dans les technologies et la santé.

  \item \textbf{Évolution temporelle} : L'analyse chronologique montre une augmentation progressive de l'influence des facteurs environnementaux entre 2015 et 2023, reflétant la prise de conscience croissante des risques climatiques.
\end{enumerate}

\subsection{Interprétabilité et limites des modèles ML en finance}

L'interprétabilité des modèles constitue un enjeu crucial dans le domaine financier, où les décisions doivent être justifiables et les risques clairement identifiés. Plusieurs approches ont été mises en œuvre pour "ouvrir la boîte noire" des modèles de Machine Learning :

\subsubsection{Techniques d'interprétabilité globale}
\begin{itemize}
  \item \textbf{SHAP (SHapley Additive exPlanations)} : Calcul de la contribution marginale de chaque variable à la prédiction finale, basé sur la théorie des jeux coopératifs.
  \item \textbf{Importance par permutation} : Mesure de la dégradation des performances lorsqu'une variable est aléatoirement permutée.
  \item \textbf{Graphiques de dépendance partielle (PDP)} : Visualisation de la relation entre une variable explicative et la prédiction du modèle, toutes choses égales par ailleurs.
\end{itemize}

\subsubsection{Techniques d'interprétabilité locale}
\begin{itemize}
  \item \textbf{LIME (Local Interpretable Model-agnostic Explanations)} : Approximation locale du modèle complexe par un modèle linéaire interprétable.
  \item \textbf{Explications contrefactuelles} : Identification des changements minimaux nécessaires pour modifier la prédiction.
\end{itemize}

Ces méthodes ont permis d'identifier plusieurs relations non-linéaires significatives, notamment :

\begin{enumerate}
  \item \textbf{Effet de seuil pour l'intensité carbone} : L'impact sur le risque de crédit devient particulièrement marqué au-delà de certains seuils sectoriels, suggérant une perception de risque accru par les investisseurs.

  \item \textbf{Effets d'interaction entre gouvernance et performance financière} : Une bonne gouvernance amplifie l'effet positif des indicateurs financiers solides, mais atténue l'impact négatif des faiblesses financières.

  \item \textbf{Relation complexe entre controverse et spread} : L'effet des controverses ESG varie selon leur nature, leur gravité et la réponse de l'entreprise, avec des impacts différenciés selon les secteurs.
\end{enumerate}

Malgré ces avancées en matière d'interprétabilité, plusieurs limitations persistent :

\subsubsection{Limites liées aux données}
\begin{itemize}
  \item Historique limité des données ESG de qualité (généralement post-2015)
  \item Hétérogénéité des méthodologies de scoring entre fournisseurs
  \item Biais potentiels dans la couverture des entreprises plus petites ou émergentes
\end{itemize}

\subsubsection{Limites méthodologiques}
\begin{itemize}
  \item Risque de surapprentissage sur des périodes historiques spécifiques
  \item Difficulté à modéliser des événements rares ou sans précédent
  \item Complexité d'interprétation des interactions entre nombreuses variables
\end{itemize}

\subsubsection{Limites opérationnelles}
\begin{itemize}
  \item Nécessité d'intégrer l'expertise humaine pour contextualiser les résultats
  \item Défi de la mise à jour régulière des modèles face à l'évolution des normes ESG
  \item Enjeux de gouvernance des modèles et de confiance des utilisateurs
\end{itemize}

Ces limites soulignent l'importance d'une approche prudente dans l'application des modèles de Machine Learning au risque de crédit, combinant puissance prédictive des algorithmes et expertise financière humaine.